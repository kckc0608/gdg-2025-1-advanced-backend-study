회계사들이 장부를 수정할 때는 '수정한다는 내용' 을 가진 새로운 항목을 추가해서 수정한다.

절대 기존 항목을 건들여서 수정하지 않는다. (회계 조작에 해당)



비슷하게 불변 스토리지 구조도 이미 저장된 파일에 대해 수정을 허용하지 않는다.

대신 새로운 레코드를 새로운 파일에 추가하고, 최종 값을 확인할 때는 (또는 값이 없다는 것을 확인할 때는) 여러 파일에 있는 레코드 값을 다시 역으로 조합하여 확인한다. (가변 스토리지에서는 디스크에 있는 값을 그 안에서 바로 수정했었다)



불변 데이터 구조는 함수형 언어에서 자주 사용되며, 안정성 특징 때문에 점점 유명해지고 있다.

한번 생성된 데이터는 절대 변하지 않으므로, 한번 쓰인 값에 대해 동시 접근이 가능하고, 특정 레코드에 대한 무결성이 자동으로 보장되기 때문이다.



높은 계층에서는 스토리지에 있는 데이터를 다루는 방법과 스토리지 밖에 있는 데이터를 다루는 방법을 엄격하게 구분한다.

내부적으로 불변 파일은 여러개의 복사본을 가질 수 있으며, 최근에 쓰여진 값이 오래된 값을 덮어쓴다.

반면 가변 파일은 일반적으로 최근 값 하나만을 보유한다.

값에 접근할 때 불변파일은 여러 복사본을 하나로 조합하는 처리과정이 필요하다.



LSM Tree (Log-Structured Merge Tree) 는 대표적인 불변 자료구조의 예시이다.

불변 LSM 트리는 append-only 스토리지를 사용하며, 변경사항을 하나로 병합하는 과정을 수행한다.

반면 가변 자료구조의 대표적 예시인 B-Tree 는 디스크에서 데이터를 탐색한 뒤, 그 페이지를 수정하여 값을 업데이트 한다.



이렇게 파일 내부에서 값을 수정하는 방식은 읽기 성능이 좋은 장점이 있지만, 쓰기 성능은 비용이 발생하는 특성을 가진다.

값을 읽을 때는 읽은 값을 바로 돌려주면 되지만, 값을 쓸 때는 값을 쓸 위치를 매번 찾아야 하기 때문이다. (조회 연산을 함께 수행)

반면 LSM 트리같이 append-only 구조를 사용하면 쓰기를 수행할 때 기존 값을 찾을 필요없이 그냥 새로 추가해서 쓰면 되므로 간단하지만, 조회할 때는 여러 쓰기 복제본을 모아서 하나로 병합하는 추가적인 처리과정이 필요하므로 비용이 발생하는 특성을 가진다.



가변 B-Tree 가 사용하는 구조와 트리 구성 방법 때문에, 대부분의 읽기 / 쓰기 / 트리 재구성에 들어가는 디스크 I/O 는 랜덤 엑세스이다.

각각의 쓰기 연산은 일단 페이지를 탐색하는 과정을 거쳐야 하기 때문이다.

또한 페이지의 크기는 고정되어 있고, 페이지 내부에는 추가적인 쓰기 연산을 위한 여분 공간을 남겨두어야 한다.

게다가 페이지 셀 하나가 수정될 때도 전체 페이지를 다 다시 써야하는 문제도 있었다.



그래서 다른 대안으로 I/O 연산을 순차적으로 만들고, 수정하는 동안 페이지를 다시 쓰지 않도록 하는 방법이 존재한다.

그리고 이 방법이 바로 불변 구조를 사용하는 것이다.



지난 글에서 다양한 B-Tree 변형을 보며 다양한 불변 구조를 B-Tree 변형체에서 확인했었다.

이번 글에서는 LSM Tree 라는 새로운 불변 구조에 대해 알아본다.









지난 글에서 B-Tree 변형에 대해 이야기 할 때, 공간 증폭, 쓰기 증폭 문제를 버퍼링을 사용해서 해결할 수 있다고 결론지었었다.

일반적으로 버퍼링을 서로 다른 자료구조에 사용할 수 있는 방법으로 2가지가 있다.



1. 디스크에 존재하는 페이지에 대한 쓰기 연산 전파를 최대한 지연시킨다. (FD Tree, WiredTiger 등)

2. 쓰기 연산을 sequential 하게 만든다.



LSM Tree 는 버퍼링과 append-only 스토리지를 사용해서 sequential write 를 수행한다.

LSM Tree 는 B-Tree 와 유사한 디스크 기반 구조로서, 노드가 가득 차면 sequential 디스크 접근을 최적화한다.



LSM Tree 에서 Merge 는 merge sort 로 트리 데이터를 합치는 것을 가리킨다.

이 과정은 중복된 카피본을 하나로 합칠 때 일어나므로 트리 유지보수 또는 읽기 조회시 발생한다.



LSM Tree 는 data file 에 대한 쓰기 연산을 지연해서 수행하며, 변경사항을 메모리에 있는 테이블에 모아두었다가 한번에 수행한다. 메모리에 변경사항을 저장 중인 모든 레코드는 파일에 완전히 반영할 떄까지 계속해서 접근이 가능하다.



데이터 파일의 불변성을 유지하는 핵심 요인은 sequential write 이다.

데이터는 single pass 로 디스크에 쓰여지며, file 은 append-only 로 동작한다.

가변 구조는 single pass 로 블록을 미리 할당할 수 있지만 (ISAM 과 같은 경우) 연속적인 접근에는 랜덤 엑세스를 통한 읽기와 쓰기 연산이 필요하다.

불변 구조는 데이터 레코드를 순차적으로 배치할 수 있도록 해주므로 단편화 문제를 방지할 수 있다.

게다가 불변 파일은 추후 쓰기를 위한 여분 공간을 미리 잡아둘 필요가 없으므로 더 높은 밀도를 갖고 있다.



파일이 불변성을 갖고 있으면 삽입, 수정, 삭제 연산은 디스크에서 데이터 레코드를 찾을 필요가 없다.

그리고 이로 인해 쓰기 성능과 throughput 이 크게 개선된다.

반면 복제된 내용을 저장하는 것이 가능해지므로 조회하는 동안에는 복제본 간 충돌을 해결하는 과정이 필요해진다.

따라서 LSM 트리는 읽기보다 쓰기 연산이 더 자주 나타나는 상황에서 특히 적합한데, 이는 데이터의 양과 수집 속도가 빨라지는 현대 데이터 집약적 시스템과 잘 맞는다.



LSM 트리는 설계상 읽기 연산과 쓰기 연산간 교점이 존재하지 않는다.

따라서 디스크에 있는 데이터는 세그먼트 락 없이 읽기와 쓰기가 함께 일어날 수 있으며, 동시성 제어를 매우 간단히 만들어준다.

반면 가변 구조에서는 계층적 락과 래치를 사용해서 on-disk 데이터 구조의 무결성을 보장해야 하며, 동시 읽기 접근은 허용해도, 쓰기 접근에 대해서는 베타적인 서브트리 권한을 부여해야 한다.

LSM 기반 스토리지 엔진은 메모리 관점에서 선형화 가능한 데이터 파일과 인덱스 파일을 사용하며, 스토리지의 구조를 관리하는 경우에만 동시성을 제어한다.



B-Tree 와 LSM Tree 모두 성능 최적화를 위해서 어느 정도 내부 관리 로직이 필요하다.

하지만 이 둘의 내부 관리 로직이 필요한 이유는 서로 다르다.

LSM Tree 는 할당된 파일의 수가 꾸준히 증가하기 때문에 중간 중간 파일을 병합하고 다시 쓰는 과정을 통해 읽기 연산 시 조회해야 하는 파일의 수가 너무 많아지지 않도록 관리 해야 한다.

반면 가변 파일이라면 부분적으로 또는 전체적으로 다시 쓰여질 수 있으므로 단편화를 줄이기 위해 공간을 하나로 모으는 과정에서 레코드의 수정과 삭제가 발생한다.

물론 이 관리 과정의 범위는 구현에 따라 달라진다.





LSM 트리의 구조
먼저 ordered LSM Tree 부터 시작해서 구조를 파악해보자. 이 트리는 파일이 정렬된 데이터 레코드를 보유하고 있는 경우를 말한다. (뒤에서 unordered lsm storage 를 다룰 예정이다)



LSM Tree 는 작은 메모리 영역과 큰 디스크 영역의 컴포넌트로 구성된다.

불변 파일의 내용을 디스크에 쓰기 위해서는 먼저 변경 사항을 메모리에 임시 저장하고, 그 내용을 정렬해야 한다.



메모리 영역의 컴포넌트는 memtable 이라고 부르며, 가변적인 특성을 갖는다.

이 테이블은 데이터 레코드의 값을 임시저장하며, 읽기 / 쓰기 연산 수행시 그 대상에 대한 정보를 제공한다.

memtable 내용은 테이블이 일정 임계치 이상 가득차면 그 내용을 디스크에 써서 영구 저장한다.

memtable 수정에는 디스크 접근도, 그와 관련된 I/O 비용도 없다.

다만 별도의 WAL 파일이 존재하여 데이터 레코드에 대한 견고성을 보장하는 역할을 수행한다.

데이터 레코드는 로그에 추가되고나서 메모리에 저장된 다음에 client 는 연산이 수행되었다는 것을 확인할 수 있다.



결국 이 메모리 내에서 버퍼링이 수행되는 것과 같다.

모든 조회와 쓰기 연산은 memtable 에 적용되며, 데이터구조는 정렬 상태를 유지하고, 동시 접근을 허용한다.

여기에는 인 메모리 sorted tree 의 일종 또는 비슷한 성능을 내는 자료구조가 사용된다.



디스크 영역의 컴포넌트는 메모리에 버퍼링된 내용을 디스크로 flush 하여 만들어진다.

디스크 영역 컴포넌트는 오직 조회 용도로만 사용된다.

버퍼링 되었던 내용은 영구 저장되고, 파일은 절대 수정되지 않는다.

이 특성 덕분에 우리는 인 메모리 테이블에 대한 쓰기, 디스크와 인 메모리 테이블에 대한 읽기, 병합, 파일 삭제 연산에 대해서만 고려해도 되므로 더 간단하게 생각할 수 있다.





Two-Component LSM Tree
LSM 트리의 구조는 크게 Two-Component 와 Multi-Component 구조로 구분할 수 있다.

먼저 Two-Component 구조를 살펴보자.



Two-Component 구조는 변경 불가능한 세그먼트로 구성된 하나의 디스크 컴포넌트만 갖고 있다.

이때 디스크 컴포넌트는 B-Tree 로 구성되어 있으며, 노드가 100% 모두 가득 차있고, 읽기만 가능하다.



메모리 영역의 트리 내용은 디스크로 플러시 된다.

플러시를 하는 동안, 각각의 메모리 영역의 각 서브트리에 대한 플러시에 대해, 디스크에서 동일한 서브트리를 찾고, 병합된 컨텐츠를 쓰며, 디스크 영역의 서브트리를 새 세그먼트로 교체한다.

서브 트리에 대한 플러시가 끝나면, 대체된 메모리 영역 / 디스크 영역의 서브트리는 버려지며, 병합 결과 데이터로 대체된다.

이 과정은 디스크 상에서 이미 존재했던 섹션을 접근 가능하게 바꿔주는 방법으로 진행된다.



병합은 lockstep 안에서 이터레이터가 디스크 영역의 리프노드와 메모리 트리 내 컨텐츠를 읽는 과정을 반복하게 함으로써 구현한다.

이 두 데이터 소스가 모두 정렬되어 있기 때문에 새로운, 병합된, 정렬이 유지된 결과를 만드는 과정을 생성할 때, 각 영역의 이터레이터의 현재값만 알면 된다. (병합 정렬 과정에서 병합할 때 두 배열의 제일 앞 값만 비교해서 병합하는 것과 같다)



이 접근법은 사실 불변 B-Tree 에서 다뤘던 내용의 논리적 확장이자 연장선이기도 하다.

서브트리 병합과 플러시를 구현할 때, 우리는 3가지를 고려해야 한다.



1. 플러시 프로세스가 시작하면, 그 이후의 모든 쓰기 연산은 새로운 memtable 에 버퍼링해야 한다.

2. 서브트리 플러시가 진행되는 동안, 디스크 영역과 플러시가 진행중인 메모리 영역의 서브트리는 읽기에 대해 계속해서 접근이 가능해야 한다.

3. 플러시가 끝나면 병합된 내용을 반영해야 하며, 병합되지 않은 디스크, 메모리 영역의 내용은 버려야 하는데, 이 연산들은 모두 원자적으로 진행되어야 한다. (일부만 성공할 수 없다. 모두 성공하거나 모두 실패해야 한다.)



two-component 구조는 매우 간단하지만, 이것만으로도 인덱스 파일을 유지보수하는데에는 충분히 유용하지만, 아직까지 이를 구현한 사례는 없었다고 한다.

왜냐하면 이 접근 방법의 쓰기 증폭 특성 때문인데, memtable 이 플러시 될 때마다 트리거되는 병합 연산이 상대적으로 자주 일어나기 때문이다.



Multicomponent LSM Tree
multicomponent 구조는 하나 이상의 디스크 영역 테이블을 갖고 잇는 구조를 말한다.

이 경우, 전체 memtable 내용이 하나의 single run 안에서 모두 플러시된다.



여러번의 플러시를 하고 나면, 여러개의 디스크 영역 테이블이 만들어진다.

그리고 이 수는 점점 증가한다.

우리는 어떤 테이블이 필요한 데이터 레코드를 갖고 있을지 항상 알 수 없으므로, 여러개 파일에 모두 접근해서 데이터를 찾아야 한다.

이렇게 여러개 소스로부터 데이터를 읽는 것은 하나를 읽는 것보다 비용이 많이 발생한다.

이 문제를 해결하기 위해, 그리고 테이블의 수를 최소화하기 위해, compaction 이라는 주기적인 병합 프로세스를 실행시킨다.



compaction 은 일부 테이블을 고르고, 데이터를 읽어서 병합한 뒤, 그 결과를 새롭게 하나로 합쳐진 파일에 쓴다.

이전 테이블은 새롭게 병합된 테이블이 나타남과 동시에 버려진다.



데이터의 life cycle 을 따라가보면

먼저 데이터는 메모리 영역 컴포넌트에 버퍼링 된다.

이 영역이 너무 커지면, 내용이 디스크로 플러시되어 디스크 영역 테이블이 생성된다.

이후에 여러 테이블이 하나의 더 큰 테이블로 병합된다.



이제 뒤에서 multicomponent LSM Tree 와 관련된 여러 동작을 더 자세히 살펴볼 예정이다.





In-memory table
memtable 의 플러시 연산은 주기적으로 수행될 수도, 특정 사이즈 임계치 기준에 따라 수행될 수도 있다.

플러시 연산이 수행되기 전에 memtable 은 반드시 교체되어야 한다. (switched)

하나의 새로운 memtable 이 할당되고, 이 memtable 은 이후에 들어오는 새 쓰기 연산에 대한 버퍼링을 수행한다.

이전 memtable 은 flush state 로 바뀌어 내용을 flush 하는 과정을 수행한다.



이 두 단계는 반드시 원자적으로 수행되어야 한다.

flush state 에 있는 memtable 은 완전히 flush 되기 전까지는 계속해서 읽기 연산에 대해서는 접근 가능해야 한다.

완전히 flush 가 끝나면 이전 memtable 은 버려지고, 이로부터 만들어진 디스크 영역의 테이블이 읽기 연산에 대해 접근된다.



메모리 내에서도 데이터는 정렬되어 있으므로, 디스크 영역의 테이블은 메모리 영역의 테이블을 순차적으로 디스크에 쓰므로서 동일하게 정렬된 형태의 테이블로 만들어낼 수 있다.

플러시를 하는 동안 flushing memtable 과 current memtable (새로 만들어진 memtable) 모두 읽기 연산에 대응할 수 있다.

memtable 이 완전히 플러시 되기 전까지, memtable 내용의 디스크 영역 버전은 WAL 에만 저장되어 있다.

완전히 디스크로 플러시가 된 후에 이 로그와 로그 섹션(memtable에 적용된 연산들에 대한 로그)은 버려진다.





삽입, 수정, 삭제 연산
LSM 트리에서 삽입, 수정, 삭제 연산은 데이터 레코드의 탐색을 필요로 하지 않는다.

대신 중복된 레코드를 만들고, 조회할 때 이를 조합하여 값을 읽어들인다.



따라서 다른 디스크나 메모리 영역의 테이블에 같은 키를 가진 레코드들이 저장되어 있을 수 있기 때문에, 데이터 레코드를 memtable 에서 제거하는 것만으로는 레코드를 삭제했다고 할 수 없다.

만약 우리가 memtable 에서 레코드를 삭제하는 것만으로 데이터 삭제를 구현한다면, 이전 값을 되살리거나, 이전 값에 영향을 미치지 않는 삭제 연산이 발생할 것이다. (?)



예를 들어보자.

플러시된 디스크 영역 테이블은 데이터 레코드 V1 을 K1 을 키로 하여 갖고 있고, memtable 은 새로운 값 V2 를 갖고 있다고 해보자.



디스크에는 k1 - v1

메모리에는 k1 - v2



만약 우리가 v2 를 memtable 에서 제거하고 flush 하면 v1 을 되살리는 삭제를 하게 된다. (분명 k1 에 대한 레코드를 삭제했는데 디스크에 여전히 과거 버전의 데이터가 남아있다. 즉 삭제 연산이 수행되지 않은 셈)

k1 과 관련된 값 v1 이 존재하기 때문이다.



디스크에는 k1 - v1

메모리에는 아무것도 없음





따라서 삭제 연산은 명시적으로 기록될 필요가 있다.

이는 delete entry 를 삽입함으로서 처리할 수 있다.

(tombstone 또는 dormant certificate 라고도 부름)

이는 특정한 키에 연관된 데이터 레코드가 삭제되었다는 것을 의미한다.



디스크에는 k1 - v1

메모리에는 k1 - <tombstone>





데이터를 조회할 때 재구성하는 과정에서는 tombstone 을 이용해 shadowed value 를 필터링한다.

(tombstone 으로 표시된 레코드는 조회하지 않는다)



가끔씩 연속된 범위의 키를 삭제하는 것이 키를 하나씩 삭제하는 것보다 유리할 때가 있다.

이는 predicate delete 를 사용해 처리될 수 있는데, delete entry 를 regular record-sorting rule 을 따르는 정렬 기반으로 예측해서 삽입하는 것이다.

재구성을 하는 동안 이 predicate 와 일치하는 레코드는 skip 되어 조회되지 않는다.



predicate 는 DELETE FROM table WHERE 2 <= key and key < 4 와 같은 형태의 sql 을 처리할 때 활용된다.

아파치 카산드라는 이 접근법을 그대로 구현했으며, range tombstone 이라고 부르고 있다.

range tombstone 은 하나가 아니라 특정 영역의 여러 키를 커버한다.



range tombstone 을 사용할 때는 이를 해석하는 규칙 역시 신중하게 고려되어야 한다.

그 영역이 중첩되는 경우와 디스크 영역의 테이블 경계를 고려해야 하기 때문이다.





조회 연산
LSM 트리는 여러 컴포넌트로 구성되어 있다.

데이터를 조회할 때는 보통 하나 이상의 컴포넌트에 접근해서 내용을 읽어들이고, 이들을 병합하고 재구성해서 클라이언트에게 돌려준다. 이제 조회 과정에서 어떻게 테이블을 반복적으로 돌면서 병합하는지, 어떻게 충돌하는 레코드를 해결해서 하나로 조합하는지 그 과정을 살펴보자.



Merge-Iteration
디스크 영역 테이블의 내용이 정렬되어 있기 때문에, 우리는 multiway 병합 정렬 알고리즘을 사용할 수 있다.

예를 들어 2개의 디스크 영역 테이블과 1개의 멤테이블로 3개의 데이터 소스가 있다고 해보자.

보통 스토리지 엔진은 cursor 또는 iterator 를 제공하여 파일 내용을 탐색할 수 있도록 한다.

이 커서는 가장 마지막으로 읽어들인 데이터 레코드의 오프셋 값을 갖고 있는데, 이를 통해 이터레이션이 끝났는지 판별할 수 있으며, 다음 데이터 레코드를 가져오는데 사용할 수 있다.



multiway merge-sort 는 최소힙 기반의 우선순위 큐를 사용한다.

우선순위 큐에는 최대 N개의 이터레이터를 저장할 수 있으며, 그 내부는 정렬되어 있어서 다음으로 가장 작은 요소를 반환한다.

각 이터레이터의 head 값이 우선순위 큐에 저장하면, 하나로 병합할 때 우선순위 큐에서 root 를 반복해서 꺼내오는 것만으로 3개 데이터 소스를 하나의 정렬된 형태로 병합할 수 있게 된다.



큐에서 제일 작은 요소를 꺼낸 후에는 그와 연관된 이터레이터가 다음 값을 반환해서 이 값을 우선순위 큐에 삽입한다.

삽입된 값은 힙 알고리즘에 따라 적절한 위치에 삽입되어 적절한 순서에 방출된다.



그런데 merge iteration 을 수행하다보면 같은 키를 가진 하나 이상의 데이터 레코드 만나는 경우가 생길 수 있다.

이터레이터 하나는 하나의 키에 대한 데이터 레코드만 가질 수 있으므로, 이 경우에는 같은 키를 가진 데이터 레코드가 여러 이터레이터에 걸쳐서 여러군데 저장되어있었음을 나타낸다.



이 과정의 복잡도를 계산해보면, O(N) 의 메모리 공간복잡도와 우선순위 큐 유지보수에 대해서는 평균적으로 O(log N) 시간복잡도로 나타낼 수 있다.





Reconciliation
Merge-Iteration 은 여러 소스로부터 받아온 데이터를 정렬할 때 어떻게 하는지만을 보여준다.

실제로 데이털르 병합해서 하나의 파일로 만들려면 여기에 더해 reconciliation 과 같은 키를 가진 데이터 레코드를 만났을 때 conflict resolution 까지 고려해야 한다.



서로 다른 테이블은 같은 키를 가진 데이터 레코드를 가지고 있을 수 있다.

(예를 들면 한쪽에서는 update, 한쪽에서는 delete 를 갖고 있는 상황)

그리고 이 contents 는 하나로 합쳐져야 한다. (reconciled)



위에서 본 우선순위 큐 구현은 같은 키에 대한 여러 값에 대해서도 동작이 가능해야 하며, 이 경우 reconciliation 동작을 발생시킨다.

데이터 레코드를 병합하기 위해서 우리는 그 데이터 간의 우선순위를 결정해야 한다.

데이터 레코드는 필수적으로 타임스탬프 같은 그 자체에 대한 메타데이터를 가지고 있다.

따라서 같은 키를 가진 데이터 레코드간 우선순위를 판별할 때는 이 메타데이터 (타임스탬프) 를 가지고 비교해서 결정한다.

높은 타임스탬프를 가진 레코드에 의해 가려진 레코드는 클라이언트에게 반환되지도, compaction 단계에서 쓰여지지도 않는다.



유지보수
가변 B-Tree 와 비슷하게, LSM Tree 도 유지보수 과정이 필요하다.

B-Tree 에서는 유지보수 과정에서 사용되지 않는 cell 을 모으고, 페이지에서 단편화된 조각을 제거한다.

LSM Tree 에서는 디스크 영역의 테이블이 꾸준히 증가하기 때문에 주기적인 compaction 작업을 실행해서 수를 줄인다.



compaction 은 위에서 본 것처럼 여러개의 디스크 영역 테이블을 골라 이들의 전체 내용을 순회하여 하나의 새로운 테이블로 병합하여 새로 쓴다.

물론 디테일한 방법은 구현마다 차이가 있다.



compaction 과정이 수행되는 동안 read 연산은 여전히 가능해야 한다.

따라서 디스크에는 compaction 결과가 쓰여질 충분한 공간이 확보되어 있어야 한다.

또한 compaction 과정은 언제든 동시에 진행될 수 있다.

물론 이 과정에서 병합하는 테이블의 각 집합은 서로소이다.

compaction 을 수행하는 compaction writer 는 여러 테이블을 하나의 테이블로 합치는 것도, 하나의 테이블을 여러 테이블로 쪼개는 것도 모두 할 수 있다.



참고로 compaction 과정에서 thombstone 을 만났을 때 이를 바로 버리지는 않는다.

구현에 따라 차이가 있지만 Rocks DB는 tombstone 이 들어있는 노드가 리프 노드가 될 때까지 보유하고, 카산드라는 GC 에 의해 수집될 때까지 보유한다. tombstone 이 없으면 다른 노드가 가진 복사본에 의해 데이터가 다시 보이는 문제가 발생할 수 있기 때문에 최대한 보유하고 있는다.



Leveled compaction
compaction 에는 여러가지 전략이 있다.

그 중 자주 사용되는 compaction 전략은 leveled compaction 이다.

leveled compaction 은 디스크 영역 테이블을 여러 레벨로 분할한다.

테이블의 각 레벨은 특정 사이즈를 갖고 있으며, 각 레벨은 레벨을 식별하는 식별자를 갖고 있다.

가장 높은 레벨은 bottommost level 이라고 부른다.



level 0 레벨 테이블은 memtable 로부터 갓 만들어진 테이블이다.

이 테이블 내에는 겹치는 key range 가 존재할 수 있다.

만약 level 0 테이블이 특정 임계치에 다다르면 이 내용을 합쳐서 새로운 테이블을 만든 뒤 level 1로 내린다.

level 1 이상의 테이블에서는 key range 가 겹치지 않는다.

따라서 level 0 테이블을 병합할 때는 partition 과정을 수행해야 한다. (따라서 레벨이 높아질 수록 해당 레벨에 존재하는 테이블 수가 증가함)



이렇게 key range 에 따라 테이블을 나누면 특정 키 영역에서 데이터를 읽을 때 조회하는 테이블의 수가 감소하는 효과가 있다.

이는 테이블이 가진 메타데이터를 조회함으로써 사전에 어떤 테이블을 탐색할 지 결정하는 과정으로 구현된다.



각 레벨에서는 테이블 크기의 제한, 테이블 개수의 제한이 있다.

만약 테이블 개수가 임계치를 넘으면 병합해서 다음 레벨로 보낸다. (이 과정에서 key range 가 겹치게 된다)

테이블의 크기 역시 레벨이 증가할 때마다 지수적으로 증가한다.



Size-tiered compaction
또 다른 유명한 compaction 전략으로는 size-tiered compaction 이 있다.

이 방식은 디스크 영역의 테이블을 레벨이 아니라 크기를 기준으로 그룹핑한 것이다.

작은 테이블은 서로 모여 그룹을 이루고, 큰 테이블은 큰 테이블끼리 모여서 그룹을 이룬다.



level 0 은 제일 작은 테이블들의 그룹으로, 메모리에서 갓 플러시된 테이블들이다.

테이블이 머지될 때마다 크기가 증가하며 다음 레벨의 그룹으로 이동한다.



다만 이 방식에는 테이블 기아 문제가 있다.

만약 머지한 테이블의 크기가 그럼에도 불구하고 너무 작다면 (가려진 레코드가 많다거나)

큰 레벨임에도 불구하고 갖고 잇는 실제 의미있는 데이터 수가 적을 수 있고, 이는 조회 비용이 증가함을 의미한다.

이 경우 강제로 compaction 을 더 수행한다.



이 외에도 다양한 compaction 전력이 존재한다.

카산드라는 a time window compaction strategy 를 추가로 사용하며, 이는 time-series 워크로드에 적합한 전략이다.