# Recovery 개요

데이터베이스는 독립적으로 동작하고, 문제를 해결하는 하드웨어와 소프트웨어 레이어로 구성되어있다.

데이터베이스는 그 자체로 (즉, 데이터베이스를 구성하는 하드웨어, 소프트웨어 컴포넌트는) 언제든 동작에 문제가 생길 수 있다.

따라서 데이터베이스를 구현할 때는 문제가 발생하더라도 'write' 가 수행되기로 정해진 동작에 대해서 이 동작이 확실히 수행되도록 보장할 필요가 있다.



WAL (Write-Ahead Log, 또는 commit log 라고도 함) 는 append-only 특성을 가진 디스크 기반 보조 자료구조로서, 충돌이 발생했을 때 트랜잭션을 복구하는 용도로 사용된다.

지난 글에서 정리한 페이지 캐시를 통해, 각 페이지 내용에 대한 변경 사항을 메모리에 임시 저장할 수 있었다.

이 임시저장 데이터가 실제로 디스크에 쓰여지기 전까지는 (flushed back) WAL에 각 쓰기 연산 내역을 복사하여 저장해둔다.



WAL 의 주요 기능을 간단히 요약해서 적으면 다음과 같다.

- DBMS 의 durability 특성을 보장하기 위해, 페이지 캐시가 디스크 페이지에 대한 update 동작을 임시 저장하도록 한다.

- 캐시된 페이지가 어떤 연산들에 영향을 받았다면, 디스크와 동기화가 될 때까지 그 연산들을 저장해둔다. (persist)

- 충돌이 발생하여 메모리에서만 적용된 변경사항이 유실되었다면, 로그를 기반으로 변경사항을 복구한다.



또한 ARIES (Algorithm for Recovery and Isolation Exploiting Semantics) 라는 최근 알고리즘에 대해서도 정리할 것이다.





* 참고

Postgresql 은 '체크포인트' 를 사용하여 index file, data file 에 대한 수정사항이 log file 의 특정 레코드 내용까지는 확실하게 반영되었음을 보장한다.

'체크포인트' 가 만들어졌다는 것은 주기적으로 돌고있는 '체크포인트 프로세스' 가 특정 체크포인트 영역까지는 모든 dirty page 를 디스크에 flush 했다는 것을 의미한다.

이때 dirty page 를 디스크와 동기할 때 내부적으로는 fsync() 라는 커널 call 을 사용하며, 이 시스템 콜은 dirty flag 를 비활성화 시킨다. 그리고 만약 디스크에 flush 가 제대로 되지 않았다면 에러를 응답한다.



그런데 리눅스와 일부 운영체제에서는 fsync() 시스템 콜이 I/O 에러로 flush 에 실패했음에도 dirty flag 를 비활성화시키는 경우가 있다. 게다가 이 에러는 I/O 가 실패한 순간에 열려있던 file descriptor 에게만 전달되어, 만약 file descriptor 가 열리기 전에 에러가 발생했다면, 이 file descriptor 를 사용하는 fsync() 시스템 콜은 에러를 리턴하지 않는다.



체크포인터는 특정 순간에 어떤 파일이 열려있고 안 열려있는지 파악하고 있지 않기 때문에, 특정 파일에서 발생한 error 를 놓칠 수 있다. 에러가 발생했음에도 dirty flag 를 비활성화 처리되면 체크포인터는 해당 파일이 성공적으로 동기화되었다고 간주하기 때문이다.



이러한 동작은 복구가 가능한 에러 상황임에도 불구하고, 데이터 유실 또는 데이터베이스 손상을 일으킬 수 있다.

게다가 이런 동작들은 감지하기가 힘들고, 어떤 경우에는 이 동작으로 인한 결과를 복구할 수 없는 경우도 있다.

따라서 복구 메커니즘을 구현할 때는 가능한 모든 실패 시나리오를 테스트하고, 꼼꼼하게 신경써서 구현해야 한다.





Log Semantics
WAL 은 append-only 로그로서, 이 로그에 대한 쓰기 동작은 반드시 연속적이다.

WAL 에 로깅된 데이터는 수정되지 않기 때문에 로그를 읽는 프로세스는 로그를 쓰는 프로세스가 계속해서 로깅 데이터를 추가하고 있더라도 안전하게 데이터를 읽어들일 수 있다. (물론 로그를 쓰고있는 위치에 대해서 바로 읽어들이면 안되니, 읽어들일 수 있는 경계선 - lastest write threshold 가 존재한다)



WAL 은 다수의 로그 레코드로 구성되어 있다.

각 레코드는 계속 증가하는 유일한 log sequence number (LSN) 를 갖고 있다.

LSN 값은 내부 타임스탬프나 카운터를 사용하여 표현한다.



로그 레코드는 전체 디스크 블록을 반드시 채우고 있을 필요가 없기 때문에, 이 내용은 log buffer 에 캐시되어 있다가 'force' 연산이 수행될 때 디스크로 flush 된다.

force 연산은 로그 버퍼가 가득 찼을 때 발생하며, 트랜잭션 매니저나 페이지 캐시가 요청하는 경우에도 발생할 수 있다.

이 연산이 발생하면, 모든 로그 레코드가 LSN 순서에 따라 디스크로 flush 된다.



WAL 은 디스크에 대한 operation 로그 외에도, transaction 완료를 지시하는 레코드도 갖고 있다.

이 레코드가 실제 디스크에 flush 되어야만 트랜잭션이 커밋된 것으로 간주된다.



기본적으로 WAL 은 '내가 지금 수행하려는 동작' 에 대한 로그를 남긴다.

(이름이 Write-Ahead Log 인 이유는 동작을 수행하기에 앞서 일단 로그를 먼저 남겨두고 동작을 수행하기 때문에 붙은 이름이다)

그런데 이 외에도 어떤 DBMS는 WAL 에 CLR (compensation log records) 를 저장하기도 한다.

이 로그는 롤백 또는 복구 과정에서 충돌이 발생한 경우, undo 동작을 수행하는데 사용되어 시스템이 계속 올바르게 동작하도록 한다.



WAL 은 보통 메인 저장소(디스크)와 밀접하게 결합되어 있다.

WAL 과 디스크 사이에는 인터페이스가 있으며, 특정 '체크포인트' 에 도착할 때마다 인터페이스를 통해 로그를 잘라낸다.

로그를 잘라낸다는 것은 로깅해두었던 정보를 실제 디스크에 써서 디스크와 페이지 캐시를 동기화시킨 뒤, 로그를 제거하는 것을 말한다.

(안그러면 데이터베이스의 최초 상태부터 지금의 DB 상태에 다다르는 모든 로그를 보관해야 하는데, 현실적으로 불가능하다)

다만 이렇게 '로그를 잘라내는 것' 과 '로그 정보를 디스크에 반영하는 것' 사이에 아주 조금의 불일치라도 발생한다면 데이터 유실로 이어지기 때문에 데이터베이스에서 '로깅'은 매우 중요하면서도 제대로 동작하도록 만드는 것이 어려운 요소이다.



'체크포인트' 는 로그의 특정 레코드까지는 완벽하게 디스크에 영구적으로 반영되어 더 이상 로그로서 저장할 필요가 없음을 나타내는 방식이다.

이 체크포인트 덕분에 데이터베이스가 최초로 시작할 때 수행해야 하는 일의 양을 줄일 수 있다.

sync checkpoint 라고 부르는 프로세스는 모든 dirty 페이지를 디스크에 flush 하여, 로그와 주 저장소를 완전히 동기화시킨다.



모든 내용을 디스크에 플러시하는 것은 실용적이지 않을 뿐더러 checkpoint 작업이 끝날 때까지 모든 기능을 잠시 중지시켜야 하기 때문에 대부분의 DBMS 는 fuzzy checkpoints 를 사용한다.

조금 더 자세히 정리하면 로그 헤더에 저장된 last_checkpoint 는 가장 최근에 성공한 checkpoint 정보를 갖고 있다.

fuzzy checkpoint 는 begin_checkpoint 로 가리키는 특정 로그 레코드부터 end_checkpoint 로 가리키는 특정 레코드까지의 dirty page 정보와 트랜잭션 테이블 정보를 갖고 있다.

이 레코드와 연관된 모든 페이지가 플러시 되기 전까지 이 체크포인트는 incomplete 상태로 간주된다.

모든 페이지는 비동기적으로 플러시되며, 플러시가 끝나면 last_checkpoint 레코드는 begin_checkpoint 레코드의 LSN 으로 업데이트되고, DBMS 에서 문제가 발생하면 last_checkpoint 가 가리키는 레코드부터 복구 프로세스가 시작된다.





일부 데이터베이스는 'shadow paging' 기법을 사용하여 로깅한다.

이 기법은 data durability 와 트랜잭션의 atomicity 를 보장하기 위해 사용하는 copy-on-write 기법이다.

말 그대로 쓰기 작업을 수행할 때 페이지 복사본에 대해 쓰기 작업을 수행하는 것이다.

새로운 데이터를 쓸 때는 복사된 새로운 shadow page 에 쓰고, 쓰기가 끝나면 포인터를 기존 페이지에서 새로 만들어진 shadow page를 가리키도록 단순하게 바꿔줌으로서 새로 데이터가 쓰여진 것처럼 보이게 만든다.



DBMS 의 '상태 변화' 는 'before image' 와 'after image' 를 통해 나타낼 수도 있고, redo / undo 연산의 나열로 표현할 수도 있다.

before image 에 대해서 redo 연산을 수행하면 after image 가 나오고, after image 에서 undo 연산을 수행하면 before image 가 나온다.



이와 관련하여 데이터를 로깅할 때는 크게 physical log 와 logical log 를 사용할 수 있다.

physical log 는 위의 image 와 같이 특정 페이지의 데이터를 전체 데이터를 로깅하거나, 비트단위 변경점을 로깅하는 기법이다.

(data logging)

logical log 는 '결과' 가 아니라 '과정' 을 로깅하는 것으로, 현재 상태를 만들기 위해 수행되었던 연산들을 로깅한다.

이때 로깅하는 연산은 과거에서 현재로 오는 forward, 현재에서 과거로 가는 backward 모두 로깅한다.

(operation logging)



실제로는 이 두 로깅 방식을 모두 활용해서 로깅한다.

physical log 는 undo 를 처리하는데 활용되고 (동시성제어와 성능 관련)

logical log 는 redo 를 처리하는데 활용된다. (복구하는데 걸리는 시간을 개선)





Steal & Force 정책
메모리에 캐싱해둔 데이터를 언제 디스크로 flush 할 지 결정하기 위해서, 데이터베이스는 steal / force 정책을 사용한다.

steal 정책은 steal policy / no-steal policy 로 구분되고, force 정책은 force policy / no-force policy 로 구분된다.

그리고 이 둘은 서로 조합되어 사용될 수 있기 때문에, 4가지 조합의 정책을 사용할 수 있다.

이 정책이 적용되는 곳은 페이지 캐시이지만, 개념적으로는 로깅과 복구를 다룰 때 더 자주 등장한다.



Steal Policy
steal 정책은 이름 그대로 '메모리에서 데이터를 뺏어와서 디스크에 내보내는'  정책이다.

더 구체적으로, 어떤 트랜잭션에 의해서 페이지가 수정되었고 (dirty page), 이 페이지를 디스크에 flush 하려는 상황을 생각해보자.

steal 정책을 사용한다면 이 페이지를 수정하는데 관여한 트랜잭션이 커밋되기 이전에도 디스크에 페이지 변경사항을 flush 할 수 있다.

반면 no-steal 정책은 아직 커밋되지 않은 트랜잭션이 수행한 동작의 결과는 디스크에 쓸 수 없다.

즉, 커밋되지 않은 트랜잭션이 만들어낸 변경사항을 미리 뺏어서 디스크에 보낼 수 있도록 허용할 것인지를 결정하는 것이다.



Force Policy
force 정책은 거꾸로 트랜잭션 관점에서 보는 정책으로,

force 정책을 적용하게 되면, 트랜잭션이 커밋되기 위해서 그 트랜잭션이 변경을 일으킨 모든 페이지를 반드시 디스크에 flush 해야만 한다.

no-force 정책에서는 디스크에 flush 를 하지 않아도 트랜잭션을 커밋할 수 있다.



이 두 정책은 데이터베이스의 redo / undo 연산과 관련된 내용을 갖고 있기 때문에 잘 이해하는 것이 중요하다.

Undo 는 커밋된 트랜잭션에 의한 페이지 변경을 되돌리는 것을 말하고,

Redo 는 커밋된 트랜잭션에 의해 변경사항을 디스크에 반영하는 것을 말한다.



no-steal 정책을 사용하면 redo 연산만을 가지고 복구를 구현할 수 있다.

디스크에는 오직 커밋된 트랜잭션에 의한 변경점만이 저장되어 있고, WAL 에는 커밋되지 않은 작업 내역만이 저장되어 있으므로,

디스크에서 과거 버전의 페이지를 가져온뒤, WAL 에 로깅된 데이터를 하나씩 다시 실행하면 (redo) 원래 보고 있었던 페이지를 복구할 수 있다.



no-force 정책을 사용하면 디스크에 flush 하지 않고도 페이지에 대한 업데이트 내용을 저장해둘 수 있다.

이 경우에는 더 많은 페이지 캐시가 필요할 것이다. 



force 정책을 사용하면 충돌로 인한 복구과정에서 커밋된 트랜잭션을 다시 구성하는 추가적인 작업을 할 필요가 없다.

트랜잭션을 커밋할 때마다 디스크에 반드시 flush 를 수행하므로, 이미 디스크에 커밋된 트랜잭션이 반영되어있기 때문이다.

(no-force 라면 디스크에 flush 되지 않았지만 commit 된 트랜잭션은 반드시 다시 구성해내야만 한다)

하지만 이 정책은 '트랜잭션을 커밋할 때마다' 반드시 디스크에 flush 를 수행해야 하므로, 디스크 I/O 작업에 의해 커밋에 시간이 비교적 오래걸린다는 단점이 있다.



일반적으로 트랜잭션이 커밋되기 전까지, 우리는 그 트랜잭션 속 동작을 되돌릴 수 있는 정보를 충분히 가지고 있어야 한다.

특히, 그 트랜잭션이 커밋되기 이전에 내용물이 디스크에 flush 가 되었다면 (steal  정책 사용), 그 커밋을 롤백할 때까지는 undo 연산을 수행하는데 필요한 정보를 계속 가지고 있어야 한다. 반면 redo 연산과 관련된 로그의 경우에는 커밋이 될 때까지만 보관하면 된다.

이로부터 트랜잭션은 undo 또는 redo 연산에 대한 로그가 작성되기 전에는 커밋될 수 없다는 것을 알 수 있다.



ARIES
aries 는 steal / no-force 정책을 사용하는 복구 알고리즘이다.

이 알고리즘은 physical redo 연산을 사용하여 복구 과정에 대한 성능을 개선하고, (변경점을 빠르게 반영할 수 있으므로)

일반적인 동작에 대해서는 logical undo 연산을 사용하여 동시성 문제를 해결한다. (logical undo 연산은 각 페이지마다 독립적으로 적용할 수 있으므로)

이 알고리즘은 WAL 레코드를 사용하여 복구 과정의 repeating history 를 구현함으로써 커밋되지 않은 연산이 수행되지 않은 데이터베이스의 마지막 상태를 재구성할 수 있다. 그리고 커밋되지 않은 연산들은 undo 과정에서 만들어진 compensation log records 를 통해 보관해둔다.



이 알고리즘에 따라 디스크를 장애로부터 복구하는 과정은 다음과 같다.



1. analysis phase

 페이지 캐시에 있는 dirty page 와 충돌당시 진행중이었던 트랜잭션을 식별한다.

dirty page 에 대한 정보는 redo phase 의 시작 지점을 파악하는데 활용되고,

충돌 당시 진행중이었던 트랜잭션 리스트의 경우, undo phase 에서 미완성된 트랜잭션을 롤백하는데 사용된다.



2. redo phase

이 단계에서는 history 를 반복하여 데이터베이스의 상태를 충돌이 발생했떤 그 순간으로 되돌린다.



3. undo phase

모든 미완료 트랜잭션을 롤백하고, 데이터베이스를 가장 마지막에 consistent 했던 상태로 되돌린다.

만약 데이터베이스를 복구하는 과정에서 오류가 발생하면, undo transaction 은 이 미완료 트랜잭션을 반복하지 않고 해당 undo transaction 을 로깅해둔다.



ARIES 는 LSN 을 사용하여 로그 레코드를 식별하고, dirty page table 에서 실행중인 트랜잭션에 의해 수정된 페이지를 트래킹한다.

ARIES 는 그리고 physical redo, logical undo, fuzzy checkpointing 을 사용한다.



------------------

# Concurrency Control
DBMS 아키텍처를 정리할 때, 동시성 제어를 위해 lock manager 와 transaction manager 를 활용한다고 했었다.

이제 이에 대해서 조금 더 자세히 정리해보자.



먼저 '동시성 제어' 는 말 그대로 '동시에 실행되는' 트랜잭션 사이의 상호작용을 관리하는 방법을 말한다.

이 방법은 크게 3가지로 분류할 수 있다.



1. 낙관적 동시성 제어 (Optimistic concurrency control, OCC)

기본적으로 트랜잭션이 동시에 읽고 쓰기 작업을 수행할 수 있도록 허용한다.

그리고 각 트랜잭션들의 읽기 쓰기 작업이 직렬가능한지 (serializable) 확인한다.

(직렬가능성에 대해서는 아래에서 정리한다)

만약 실행 결과에 충돌이 발생한다면 충돌이 발생한 트랜잭션 중 하나를 abort 시킨다.



2. 멀티버전 동시성 제어 (MultiVersion Concurrency Control, MVCC)

현재 레코드에 대해 여러 버전의 타임스탬프 버전을 두어, 특정 타임스탬프 시점에서 데이터베이스의 뷰가 일관됨을 보장한다.

MVCC는 validation 기법을 사용하여, 여러 버전 중 하나의 트랜잭션만 update, commit 에 성공하도록 한다.

이 방식은 timestamp ordering 과 같은 lock 을 사용하지 않는 기법과, 2-Phase Locking 같이 lock 을 사용하는 기법이 있다.



3. 비관적 동시성 제어 (Pessimistic (conservative) Concurrency Control, PCC)

비관적 동시성 제어 기법에도 lock 을 사용하는 방식과 lock 을 사용하지 않는 방식이 존재한다.

두 방식은 공유자원에 대한 접근 권한을 얻고, 관리하는 방법이 서로 다르다.



Lock 기반의 비관적 동시성 제어는 데이터 베이스 레코드를 다룰 때 반드시 락을 걸어, 자신이 락을 해제할 때까지는 다른 트랜잭션이 이 레코드에 접근하지 못하도록 막는다.

Nonlocking 기반의 비관적 동시성 제어는 read / write 동작의 리스트를 유지하고 있고, 아직 끝나지 않은 트랜잭션에 의존하여 연산의 실행에는 제약을 둔다.

비관적 스케줄은 여러 트랜잭션이 서로가 서로의 락 해제를 기다리는 데드락 상황이 발생할 수 있는 문제점이 있다.





이번 글에서는 하나의 단일 노드 안에서 일어나는 동시성 제어를 정리할 것이다.

(분산 환경에서의 동시성 제어는 별도로 정리)



그런데 동시성 제어를 정리하려면, 먼저 이 동시성 제어를 통해 해결하고자 하는 문제를 명확히 이해하고 정의할 필요가 있다.

제일 먼저 여러 트랜잭션이 동시에 실행될 수 있는지 여부를 따지는 '직렬가능성' 에 대해서 먼저 정리해보자.





직렬가능성 (Serializability)
하나의 트랜잭션은 현재 데이터베이스 상태를 기준으로 수행되는 일련의 read / write 연산의 집합이며, 읽기 연산으로 얻은 데이터에 대해 이루어지는 비즈니스 로직을 포함한다.

'스케쥴'은 데이터베이스 관점에서 일련의 트랜잭션들을 실행하는데 필요한 전체 '연산'의 리스트를 말한다.

하나의 트랜잭션의 시작과 끝에는 begin / commit (에러가 발생하는 경우 abort 까지) 연산도 포함되므로, 하나의 스케줄 안에는 read, write, commit, abort 와 같은 연산들이 혼재되어 있을 것이다.

이때 스케줄이 들어있는 이 연산들은 하나의 데이터베이스 상태에 대해서 다른 사이트 이펙트를 일으키지 않는다고 가정한다.



만약 스케줄 안에 있는 모든 연산이 성공적으로 수행되었다면, 해당 스케줄에 대해 complete 되었다 말한다.

올바른(correct) 스케줄은 기존의 스케줄 내 연산들을 순서대로 실행한 것과, 성능 최적화를 위해서 연산 리스트의 일부를 중첩해서 동시에 실행하거나 순서를 바꿔서 실행한 결과가 동일하다. 즉, 일부 트랜잭션을 동시에 실행하거나, 순서를 바꿔서 실행해도 ACID 원칙을 위반하지 않고, 개별 트랜잭션을 따로따로 실행한 것과 동일한 결과를 보인다.



만약 스케줄 안에 있는 모든 트랜잭션이 완전히 독립적으로 실행된다면, (즉, 하나의 트랜잭션 실행이 온전히 끝나고 다음 트랜잭션이 실행되어 트랜잭션과 트랜잭션의 실행 사이에 중첩이 전혀 없는 상태) 이 스케줄을 가리켜 serial 하다고 말한다.

하지만 serial 한 실행 방법은 100% 안전한 실행을 보장하긴 해도 성능상 매우 좋지 않기 때문에, 서로의 실행에 영향을 끼치지 않는 트랜잭션을 중첩하여 동시에 실행하는 동시성 제어 기법을 활용하여 성능을 높일 필요가 있다.

이렇게 실제 실행은 serial 하지 않지만, 논리적인 실행결과가 serial 한 것과 동일한 스케줄을 가리켜 serializable 하다고 말한다.



보통 트랜잭션을 지원하는 DBMS 에서는 각 트랜잭션에 대해 서로 다른 Isolation Level 을 설정할 수 있도록 허용한다.

isolation level 은 뒤에서 더 자세히 정리하겠지만, 트랜잭션의 일부분이 어떻게 그리고 언제 다른 트랜잭션에게 보일 수 있고, 보여야 하는지를 정의한 것이다. 다르게 말하면 isolation level 은 트랜잭션이 동시에 실행되고 있는 다른 트랜잭션에게 '어느 정도 수준까지' 보일 것인지를 정의한 것이며, 실행하는 동안 어떤 종류의 anomaly 까지만 보이게 할 것인지를 정의한 것과 같다.



하지만 이와 같은 isolation level 을 설정하는 것은 비용이 발생한다.

아직 끝나지 않은 (커밋되지 않은) 임시 write 데이터가 다른 트랜잭션으로 퍼지는 것을 막기 위해서, 추가적인 조율과 동기화 작업이 필요하며, 이는 성능상 안좋은 영향을 주기 때문이다.



먼저 isolation level 을 설명하기에 앞서, 잠깐 언급했었던 트랜잭션이 실행되는 동안 만날 수 있는 anolmay 의 종류에 대해서 간단하게 정리하고 넘어가자.



Read / Write Anomaly
트랜잭션이 실행되는 동안 발생하는 anomaly 는 크게 read / write 2가지로 구분할 수 있다.



특히 SQL 표준에서는 트랜잭션을 동시성 환경에서 실행하는 동안 만날 수 있는 read anomaly 를 dirty read / nonrepeatable read / phantom read 3가지가 있다고 설명한다.



먼저 dirty read 는 트랜잭션이 커밋되지 않은, 다른 트랜잭션에 의해서 쓰기 작업이 발생된 데이터를 읽는 현상을 말한다.

T1 트랜잭션이 레코드에 값을 쓰고 아직 커밋하지 않은 상태라고 해보자.

이 상태에서 T2 트랜잭션이 T1 트랜잭션이 커밋되기 전에 그 수정된 값을 읽었다.

이때 T1 트랜잭션에서 문제가 발생하여, 또는 의도적으로 abort 를 수행하여 write 연산을 취소하여 원래대로 레코드 값을 되돌렸다면, T2는 결과적으로 아무도 쓴 적이 없던 (커밋된 적이 없던) 엉뚱한 값을 읽고 비즈니스 로직을 처리하게 된다.



nonrepeatable read (fuzzy read) 는 트랜잭션이 동일한 row 에 대해 두 번 질의를 수행했을 때, 그 결과가 서로 다르게 나오는 현상을 말한다.

예를 들어 T1 이 행 하나를 조회했고, T2 가 그 행을 수정한 뒤 commit 까지 하고나서, 다시 T1 이 같은 row 에 대해 읽기를 수행한다면, T1 입장에서는 같은 트랜잭션 안에서 동일한 row 의 값을 서로 다르게 보는 문제가 생긴다.



만약 우리가 이 문제의 범위를 '동일한 1개의 row' 에서 '범위 조회' 로 넓힌다면, 이 문제의 row들을 가리켜 phantom records 라고 부르며, 이 이상현상을 가리켜 phantom read 라고 부른다.

즉, 동일한 set 의 row 를 2번 조회했더니, 그 결과가 서로 다르게 나온 것이 phantom read 이다.



이번엔 write anomaly 에 대해 정리해보자.

write anomaly 에도 크게 lost update, dirty write, write skew 3가지 종류의 이상현상이 존재한다.



먼저 lost update 는 T1, T2 가 같은 레코드의 값을 수정하려고 할 때 발생한다.

T1, T2 가 거의 동시에 레코드에 접근해서 동일한 값을 읽어들이고, 이 두 트랜잭션이 서로 다른 값으로 쓰기를 해서 서로 다른 시차를 두고 commit 을 했다고 해보자. 만약 T1 이 먼저 커밋하고, T2 가 나중에 커밋을 했다면, 이 둘이 쓰기를 진행했던 기준값은 동일하기 때문에 T1 의 쓰기 값은 T2 의 쓰기값에 의해 덮어쓰여지는 문제가 발생한다.



dirty write 는 여러 트랜잭션들 중 하나가 커밋되지 않은 dirty value 를 가지고 있고, 이 값을 수정하고 커밋해서 저장하는 상황을 말한다. 즉, dirty read 문제의 연장선상으로 발생하는 문제를 말한다.



write skew 는 각각의 개별 트랜잭션은 지켜야 하는 정책을 지켰으나, 이 둘의 실행결과는 전체 정책을 위반했을 때 발생하는 문제이다.

예를 들어, 정책상 각각의 계좌 잔고 값은 음수가 될 수 있지만, 전체 계좌의 잔고 값 합은 양수가 되어야 한다고 해보자.

T1 이 계좌 1번의 값을 감소시켜 음수로 만들었고, T1 이 생각한 입장에서는 그럼에도 여전히 전체 계좌의 잔고 합이 양수였다고 한다면 T1 의 동작은 문제가 없다.

이때 T2 가 계좌 2번의 값을 감소시켜 음수로 만들었고, T1 이 계좌 1의 잔고를 감소시킨 것을 모르는 상태로 전체 잔고합이 양수라고 생각하여 T2 가 이 결과를 커밋했다고 해보자.

그러면 각 T1, T2 의 동작 입장에서는 아무런 문제가 없었지만, 두 트랜잭션이 모두 값을 감소시켜 결과적으로는 전체 계좌의 잔고 합이 음수가 되는 문제가 발생할 수 있다.



이제 이 이상현상을 기준으로 isolation level 에 대해 정리해보자.



Isolation Level
데이터베이스에서 사용하는 isolation level 은 크게 4가지로 구분된다.



먼저 제일 낮은 (느슨한) isolation level 은 read uncommitted 이다.

이 isolation level 에서는 동시에 실행중인 하나의 트랜잭션이 다른 트랜잭션의 커밋되지 않은 쓰기를 볼 수 있다.

따라서 dirty read 문제가 발생할 여지가 있다.



만약 dirty read 문제만큼은 막고 싶다면 그 다음 isolation level 인 read committed 를 적용할 수 있다.

이 isolation level 에서는 다른 트랙잭션에 의해 commit 된 데이터만 읽을 수 있기 때문에, dirty read 문제는 발생하지 않는다.

그럼에도 트랜잭션 안에서 같은 레코드를 여러 번 읽는다면, 각 조회마다 서로 다른 값을 읽어들일 수 있는 nonrepeatable read 문제는 여전히 남아있다.

만약 nonrepeatable read 문제까지 방지하고 싶다면 그 다음 레벨인 repeatable read isolation level 을 적용하면 된다.



제일 제약이 강한 isolation level 은 serializability 이다.

이 레벨에서는 트랜잭션의 결과가 전체 트랜잭션이 serial 하게 실행될 수 있을 때만 보인다.

(serializable 이 아니다)

따라서 이 레벨로 설정한다는 것은 같은 시간 동안에 트랜잭션은 중첩될 수 없다는, 사실상 동시성을 자체를 비허용한다는 것과 같다.

그러므로 결국 DB 의 성능상 좋지 않은 단점이 생긴다.



트랜잭션 중에서 다른 트랜잭션의 실행 결과에 의존하지 않는, 완전히 독립적인 트랜잭션은 하나의 스케줄 내에서 어떤 순서에 실행되든 상관없다.

serializability 는 여러 operation 들을 임의의 순서로 실행할 때 나타나는 특성이다.

따라서 serializability 에는 특정 순서로 트랜잭션을 실행시켜야 한다는 의미는 포함되어 있지 않다.

ACID 에서 isolation 은 serializability 를 의미한다.

하지만 불행히도 serializability 를 구현하려면 어느정도 조정 작업이 필요하다.



일부 데이터베이스는 snapshot isolation 을 사용한다.

이 개념에서는 하나의 트랜잭션이 자신이 시작된 이후 다른 트랜잭션들이 가하는 모든 동작을 볼 수 있다.

각 트랜잭션은 자신의 스냅샷을 가지고, 이 스냅샷 기준으로 쿼리를 실행함, 트랜잭션이 끝날 때까지 스냅샷은 변하지 않는다.

그리고 트랜잭션의 커밋은 자신이 수정한 데이터가, 자신의 트랜잭션 실행시간 동안 변하지 않았을 때만 수행할 수 있다.

(다른 트랜잭션의 모든 동작을 관찰할 수 있으므로, 다른 트랜잭션이 내가 수정한 데이터를 건들였는지 아닌지 알 수 있다)

만약 다른 트랜잭션이 자신이 수정하려는 데이터를 건들였다면 커밋할 수 없으므로 abort 하거나 roll back 한다.



결과적으로 하나의 데이터를 2개의 트랜잭션이 건든다면 이 중에 하나만 그 데이터를 수정할 수 있다.

따라서 lost update 이상현상을 방지할 수 있다.

어떤 값 V 에 여러 트랜잭션이 접근한다면 최초로 접근한 트랜잭션만 쓰기에 성공하고, 이후에 접근한 트랜잭션은 abort 되어 다시 처음부터 데이터를 읽고 쓰는 작업을 수행한다.











